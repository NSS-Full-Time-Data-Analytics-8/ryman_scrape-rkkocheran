{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd56953",
   "metadata": {},
   "source": [
    "## Web Scraping the Ryman Calendar\n",
    "\n",
    "This notebook uses BeautifulSoup to create a DataFrame of upcoming events at the Ryman. This information is available at https://ryman.com/events/, which splits the events across multiple pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2767d01",
   "metadata": {},
   "source": [
    "### Import, Verify and Format the HTML Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b73762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://ryman.com/events/list/?tribe_event_display=list&tribe_paged=1'\n",
    "ryman_html = requests.get(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd045a",
   "metadata": {},
   "source": [
    "**Verify that the URL worked and the code read in correctly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149dd592",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Status Code:',ryman_html.status_code)\n",
    "print('Status Type:',type(ryman_html))\n",
    "print('Code:')\n",
    "print(ryman_html.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a13fc",
   "metadata": {},
   "source": [
    "**Beautify the html code using a formatter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman_events_html = BS(ryman_html.text)\n",
    "print(ryman_events_html.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dbeb31",
   "metadata": {},
   "source": [
    "### Begin Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5c49a",
   "metadata": {},
   "source": [
    "**Using a webpage inspector, identify the html tags and extract the information pertaining to headliners, openers (if any), dates and times, and ticket prices. Loop over all event pages; for each event page, create and populate separate lists for each of the mentioned items. Create and populate a pandas DataFrame with this information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2ce2c",
   "metadata": {},
   "source": [
    "**First add headliners, opening acts, dates and times.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9679c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the common event webpage url\n",
    "URL = 'https://ryman.com/events/list/?tribe_event_display=list&tribe_paged='\n",
    "\n",
    "# Initate an empty DataFrame to populate with each page's event info\n",
    "events_df = pd.DataFrame(columns=['Event', 'Opener', 'Date', 'Time'])\n",
    "\n",
    "# Initiate variables to control iteration over the main loop\n",
    "page_valid = True\n",
    "page = 1\n",
    "\n",
    "# Loop through each event page on the Ryman website\n",
    "while page_valid:\n",
    "    \n",
    "    # Read in the url's html code\n",
    "    ryman_html = requests.get(URL + str(page))\n",
    "    \n",
    "    # Terminate if the url is not valid\n",
    "    if ryman_html.status_code == 404 | ryman_html.status_code == 400:\n",
    "        page_valid = False\n",
    "        break\n",
    "        \n",
    "    # Beautify the html code\n",
    "    ryman_events_html = BS(ryman_html.text)\n",
    "      \n",
    "    # Terminate if the url/page has no events\n",
    "    events = ryman_events_html.findAll('div', attrs={'id':'primary', 'class':'tribe-events-loop'})\n",
    "    if len(events) == 0:\n",
    "        page_valid = False\n",
    "        break\n",
    "    \n",
    "    # Initiate empty lists to populate with the current page's event info\n",
    "    event_list = []\n",
    "    time_list = []\n",
    "    date_list = []\n",
    "    opener_list = []\n",
    "    \n",
    "    # Loop over each event's info\n",
    "    # Event info is wrapped in: <div class='tribe-beside-image'>\n",
    "    for info in ryman_events_html.findAll('div', attrs={'class':'tribe-beside-image'}):\n",
    "        \n",
    "        # Titles are wrapped in: <a class=\"tribe-event-url>\"\n",
    "        event_list.append(info.find('a', attrs={'class':'tribe-event-url'}).get('title'))\n",
    "        \n",
    "        # Dates and times are wrapped in: <time>\n",
    "        date_time_info = info.find('time').text.upper()\n",
    "        dt_split = date_time_info.split(' AT ')\n",
    "        time_list.append(dt_split[1])\n",
    "        date_list.append(dt_split[0][dt_split[0].find(',') + 2:].title())\n",
    "\n",
    "        # OPENERS are wrapped in <span class='opener'>\n",
    "        # HOWEVER, some artists have no openers and some artists have an extra span tag\n",
    "        span_list = info.findAll('span', attrs={'class':'opener'})\n",
    "        if(len(span_list) == 0):\n",
    "            opener_list.append('None')\n",
    "        elif(len(span_list) > 1):\n",
    "            opener_list.append(span_list[1].text)\n",
    "        else:\n",
    "            opener_list.append(span_list[0].text)\n",
    "    \n",
    "    # Populate the dataframe with the new list values\n",
    "    events_df = pd.concat([events_df, pd.DataFrame({'Event':event_list, 'Opener':opener_list, 'Date': date_list, 'Time':time_list})]).reset_index(drop=True)\n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70565ae",
   "metadata": {},
   "source": [
    "##### Have a look at the events!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8403413",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e066b6",
   "metadata": {},
   "source": [
    "**Now add ticket prices (available on a separate webpage through the \"MORE INFO\" link.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bff4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the common event webpage url\n",
    "URL = 'https://ryman.com/events/list/?tribe_event_display=list&tribe_paged='\n",
    "\n",
    "# Initate an empty DataFrame to populate with each page's event info\n",
    "events_df = pd.DataFrame(columns=['Event', 'Opener', 'Date', 'Time', 'Ticket Prices'])\n",
    "\n",
    "# Initiate variables to control iteration over the main loop\n",
    "page_valid = True\n",
    "page = 1\n",
    "\n",
    "\n",
    "# Loop through each event page on the Ryman website\n",
    "while page_valid:\n",
    "    # Read in the url's html code\n",
    "    ryman_html = requests.get(URL + str(page))\n",
    "    \n",
    "    # Terminate if the url is not valid\n",
    "    if ryman_html.status_code == 404 | ryman_html.status_code == 400:\n",
    "        page_valid = False\n",
    "        break\n",
    "        \n",
    "    # Beautify the html code\n",
    "    ryman_events_html = BS(ryman_html.text)\n",
    "      \n",
    "    # Terminate if the url/page has no events\n",
    "    events = ryman_events_html.findAll('div', attrs={'id':'primary', 'class':'tribe-events-loop'})\n",
    "    if len(events) == 0:\n",
    "        page_valid = False\n",
    "        break\n",
    "    \n",
    "    # Initiate empty lists to populate with the current page's event info\n",
    "    event_list = []\n",
    "    opener_list = []\n",
    "    date_list = []\n",
    "    time_list = []\n",
    "    price_list = []\n",
    "    \n",
    "    # Loop over each event\n",
    "    # Event info is wrapped in: <div class='tribe-beside-image'>\n",
    "    for info in ryman_events_html.findAll('div', attrs={'class':'tribe-beside-image'}):\n",
    "        \n",
    "        \n",
    "        # TITLES are wrapped in: <a class=\"tribe-event-url>\"\n",
    "        event_list.append(info.find('a', attrs={'class':'tribe-event-url'}).get('title'))\n",
    "        \n",
    "        \n",
    "        # DATES and TIMES are wrapped in: <time>\n",
    "        date_time_info = info.find('time').text.upper()\n",
    "        dt_split = date_time_info.split(' AT ')\n",
    "        time_list.append(dt_split[1])\n",
    "        date_list.append(dt_split[0][dt_split[0].find(',') + 2:].title())\n",
    "\n",
    "        \n",
    "        # OPENERS are wrapped in <span class='opener'>\n",
    "        # However, some artists have no openers and some artists have an extra span tag\n",
    "        span_list = info.findAll('span', attrs={'class':'opener'})\n",
    "        if(len(span_list) == 0):\n",
    "            opener_list.append('None')\n",
    "        elif(len(span_list) > 1):\n",
    "            opener_list.append(span_list[-1].text)\n",
    "        else:\n",
    "            opener_list.append(span_list[0].text)\n",
    "               \n",
    "                \n",
    "        # TICKET information is in a separate url available in a link wrapped in: <a class='smallblackbutton'>\n",
    "        # However, some events may be cancelled or sold out\n",
    "        ticket_url = info.find('a', attrs={'class':'smallblackbutton'}).get('href')\n",
    "        ticket_html = requests.get(ticket_url)\n",
    "\n",
    "        # Check if the ticket url is valid\n",
    "        if ticket_html.status_code == 404 | ticket_html.status_code == 400:\n",
    "            price_list.append('Ticket Prices Not Available')\n",
    "        else:\n",
    "            # Beautify ticket url html code\n",
    "            ticket_info_html = BS(ticket_html.text)\n",
    "\n",
    "            # Ticket info is wrapped in: <div class='ticketdetails'>\n",
    "            ticket_info = ticket_info_html.find('div', attrs={'class':'ticketdetails'})\n",
    "            \n",
    "            # Check ticket status (sold out, canceled, missing or available) and update the list accordingly\n",
    "            ticket_status = ticket_info.find('strong', attrs={'class':'show-status-label'})\n",
    "            if ticket_status is not None:\n",
    "                if (ticket_status.text == 'sold out') | (ticket_status.text == 'canceled'):\n",
    "                    price_list.append(ticket_status.text.upper())\n",
    "                else:\n",
    "                    price_list.append(ticket_info.find('p', attrs={'class':'theprices'}).text)\n",
    "            else:\n",
    "                price = ticket_info.find('p', attrs={'class':'theprices'})\n",
    "                # Check if price is missing\n",
    "                if price is None:\n",
    "                    price_list.append('Ticket Prices Not Available')\n",
    "                else:\n",
    "                    price_list.append(ticket_info.find('p', attrs={'class':'theprices'}).text)\n",
    "                           \n",
    "    events_df = pd.concat([events_df, pd.DataFrame({'Event':event_list, 'Opener':opener_list, 'Date': date_list, 'Time':time_list, 'Ticket Prices':price_list})]).reset_index(drop=True)\n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71131c01",
   "metadata": {},
   "source": [
    "##### Have a look at the events!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
